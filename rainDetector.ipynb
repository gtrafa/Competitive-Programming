{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "rainDetector.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMYx3oBf6zyYWI2CzhZYv6k",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gtrafa/Competitive-Programming/blob/master/rainDetector.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pmqbvsodYg9f"
      },
      "source": [
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import joblib\n",
        "from keras.preprocessing import image\n",
        "from keras.applications import vgg16\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "\n",
        "# adjust image size\n",
        "from PIL import Image"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dz9G6ppTkIWB",
        "outputId": "3899054e-d8ee-4379-e9ca-9619f89b2ba8"
      },
      "source": [
        "# Path to folders with training data\n",
        "rain_path = Path(\"/rain\")\n",
        "not_rain_path = Path(\"/not_rain\")\n",
        "\n",
        "image_count = len(list(not_rain_path.glob('*.jpg')))\n",
        "print(image_count)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "909\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3hx-J4F_vap_"
      },
      "source": [
        "def adjustImage(img_begins):\n",
        "  \n",
        "  ORIG_WIDTH, ORIG_HEIGHT = img_begins.size\n",
        "  \n",
        "  diff = (ORIG_HEIGHT - ORIG_WIDTH) // 2\n",
        "  WIDTH = 64\n",
        "  HEIGHT = 64\n",
        "\n",
        "  crop_rect = (0, diff, ORIG_WIDTH, ORIG_HEIGHT - diff)\n",
        "  final_img = img_begins.crop(crop_rect)\n",
        "  final_img.thumbnail((WIDTH, HEIGHT), Image.ANTIALIAS)\n",
        "  return final_img\n"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v61qYwL5uQBA"
      },
      "source": [
        "images = []\n",
        "labels = []\n",
        "\n",
        "# Load all the not_rain images\n",
        "for img in not_rain_path.glob(\"*.jpg\"):\n",
        "\n",
        "    # Load the image from disk\n",
        "    img = image.load_img(img)\n",
        "\n",
        "    # Convert the image to a numpy array\n",
        "    #image_array = image.img_to_array(adjustImage(img))\n",
        "\n",
        "    # Add the image to the list of images\n",
        "    images.append(adjustImage(img))\n",
        "\n",
        "    # For each 'not dog' image, the expected value should be 0\n",
        "    labels.append(0)"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_TT9wD04cPWo"
      },
      "source": [
        "images = []\n",
        "labels = []\n",
        "\n",
        "# Load all the not_rain images\n",
        "for img in not_rain_path.glob(\"*.jpg\"):\n",
        "\n",
        "    # Load the image from disk\n",
        "    img = image.load_img(img)\n",
        "\n",
        "    # Convert the image to a numpy array\n",
        "    image_array = image.img_to_array(adjustImage(img))\n",
        "\n",
        "    # Add the image to the list of images\n",
        "    images.append(image_array)\n",
        "    #images.append(adjustImage(img))\n",
        "\n",
        "    # For each 'not dog' image, the expected value should be 0\n",
        "    labels.append(0)\n",
        "  \n",
        "\n",
        "# Load all the dog images\n",
        "for img in rain_path.glob(\"*.jpg\"):\n",
        "    # Load the image from disk\n",
        "    img = image.load_img(img)\n",
        "\n",
        "    # Convert the image to a numpy array\n",
        "    image_array = image.img_to_array(adjustImage(img))\n",
        "\n",
        "    # Add the image to the list of images\n",
        "    images.append(image_array)\n",
        "    #images.append(adjustImage(img))\n",
        "\n",
        "    # For each 'dog' image, the expected value should be 1\n",
        "    labels.append(1)\n",
        "\n"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-aHfoy-iV0C",
        "outputId": "c3eb8232-b997-4a9d-8633-e0ace2d588f3"
      },
      "source": [
        "print(len(labels))\n",
        "print(len(images[0]))\n"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1122\n",
            "64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nz6uwCyih6km"
      },
      "source": [
        "# Create a single numpy array with all the images we loaded\n",
        "x_train = np.array(images)\n",
        "\n",
        "# Also convert the labels to a numpy array\n",
        "y_train = np.array(labels)\n"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NiUo11Rgr1ZI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rhU1Nhbsny-y",
        "outputId": "9713ff16-ead1-4fff-eae5-eb829f5c5a97"
      },
      "source": [
        "\n",
        "# Normalize image data to 0-to-1 range\n",
        "x_train = vgg16.preprocess_input(x_train)\n",
        "\n",
        "# Load a pre-trained neural network to use as a feature extractor\n",
        "pretrained_nn = vgg16.VGG16(weights='imagenet', include_top=False, input_shape=(64, 64, 3))\n",
        "\n",
        "# Extract features for each image (all in one pass)\n",
        "features_x = pretrained_nn.predict(x_train)\n",
        "\n",
        "# Save the array of extracted features to a file\n",
        "joblib.dump(features_x, \"x_train.dat\")\n",
        "\n",
        "# Save the matching array of expected values to a file\n",
        "joblib.dump(y_train, \"y_train.dat\")"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['y_train.dat']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s8cywxuy3LHJ"
      },
      "source": [
        "# Load data set\n",
        "x_train = joblib.load(\"x_train.dat\")\n",
        "y_train = joblib.load(\"y_train.dat\")\n"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iB7sgFL13OhQ"
      },
      "source": [
        "# Create a model and add layers\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Flatten(input_shape=x_train.shape[1:]))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1, activation='sigmoid'))\n"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZ066Jz93S07",
        "outputId": "68d3c39b-b35a-4cb1-e4e0-3d0b73e89193"
      },
      "source": [
        "# Compile the model\n",
        "model.compile(\n",
        "    loss=\"binary_crossentropy\",\n",
        "    optimizer=\"adam\",\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "model.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    epochs=10,\n",
        "    shuffle=True\n",
        ")\n"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "36/36 [==============================] - 9s 5ms/step - loss: 3.0201 - accuracy: 0.8154\n",
            "Epoch 2/10\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.1366 - accuracy: 0.9804\n",
            "Epoch 3/10\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.0662 - accuracy: 0.9882\n",
            "Epoch 4/10\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.0577 - accuracy: 0.9886\n",
            "Epoch 5/10\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.1028 - accuracy: 0.9848\n",
            "Epoch 6/10\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.0441 - accuracy: 0.9922\n",
            "Epoch 7/10\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.0172 - accuracy: 0.9953\n",
            "Epoch 8/10\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.0135 - accuracy: 0.9954\n",
            "Epoch 9/10\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.0018 - accuracy: 0.9995\n",
            "Epoch 10/10\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.0110 - accuracy: 0.9969\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa96a55cd90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4mseaoRz3Z2r"
      },
      "source": [
        "# Save neural network structure\n",
        "model_structure = model.to_json()\n",
        "f = Path(\"model_structure.json\")\n",
        "f.write_text(model_structure)\n",
        "\n",
        "# Save neural network's trained weights\n",
        "model.save_weights(\"model_weights.h5\")\n"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WRbKAHh45sYv"
      },
      "source": [
        "# Load the json file that contains the model's structure\n",
        "f = Path(\"model_structure.json\")\n",
        "model_structure = f.read_text()\n",
        "\n",
        "# Recreate the Keras model object from the json data\n",
        "model = model_from_json(model_structure)\n",
        "\n",
        "# Re-load the model's trained weights\n",
        "model.load_weights(\"model_weights.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_dxhZRJ53fO"
      },
      "source": [
        "# Load an image file to test, resizing it to 64x64 pixels (as required by this model)\n",
        "img = image.load_img(\"/content/test_files/Rain01.jpg\", target_size=(64, 64))\n",
        "\n",
        "# Convert the image to a numpy array\n",
        "image_array = image.img_to_array(img)\n",
        "\n",
        "# Add a forth dimension to the image (since Keras expects a bunch of images, not a single image)\n",
        "images = np.expand_dims(image_array, axis=0)\n",
        "\n",
        "# Normalize the data\n",
        "images = vgg16.preprocess_input(images)"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2X0f9Zqw7oB8",
        "outputId": "0767ceaf-4f6a-428e-825a-f5a4ececd935"
      },
      "source": [
        "# Use the pre-trained neural network to extract features from our test image (the same way we did to train the model)\n",
        "feature_extraction_model = vgg16.VGG16(weights='imagenet', include_top=False, input_shape=(64, 64, 3))\n",
        "features = feature_extraction_model.predict(images)\n",
        "\n",
        "# Given the extracted features, make a final prediction using our own model\n",
        "results = model.predict(features)\n",
        "\n",
        "# Since we are only testing one image with possible class, we only need to check the first result's first element\n",
        "single_result = results[0][0]\n",
        "\n",
        "# Print the result\n",
        "print(\"Likelihood that this image contains rain: {}%\".format(int(single_result * 100)))"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 41 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa96a649c20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Likelihood that this image contains rain: 100%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L83JI5eK_Koh",
        "outputId": "1a8b48d0-4133-4e18-bcb7-81958e9bdda7"
      },
      "source": [
        "# Load an image file to test, resizing it to 64x64 pixels (as required by this model)\n",
        "img = image.load_img(\"/content/test_files/Rain01.jpg\", target_size=(64, 64))\n",
        "print(img)"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<PIL.Image.Image image mode=RGB size=64x64 at 0x7FA9620105D0>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "809bGQRb8pts",
        "outputId": "545bb372-8b47-4c01-b4ef-6de6a953e5d4"
      },
      "source": [
        "# evaluating testing data\n",
        "imagess =[]\n",
        "\n",
        "# Path to folders with testing data\n",
        "testing_path = Path(\"/content/test_files_not_rain\")\n",
        "\n",
        "# Load all the not_rain images\n",
        "for index, img in enumerate(testing_path.glob(\"*.jpg\"), start=1):\n",
        "\n",
        "  # Load an image file to test, resizing it to 64x64 pixels (as required by this model)\n",
        "  img = image.load_img(img, target_size=(64, 64))\n",
        "\n",
        "  # Convert the image to a numpy array\n",
        "  image_array = image.img_to_array(img)\n",
        "\n",
        "  # Add a forth dimension to the image (since Keras expects a bunch of images, not a single image)\n",
        "  images = np.expand_dims(image_array, axis=0)\n",
        "\n",
        "  # Add the image to the list of images\n",
        "  imagess.append(image_array)\n",
        "\n",
        "# Normalize the data\n",
        "images = vgg16.preprocess_input(np.array(imagess))\n",
        "\n",
        "# Use the pre-trained neural network to extract features from our test image (the same way we did to train the model)\n",
        "feature_extraction_model = vgg16.VGG16(weights='imagenet', include_top=False, input_shape=(64, 64, 3))\n",
        "features = feature_extraction_model.predict(images)\n",
        "\n",
        "# Given the extracted features, make a final prediction using our own model\n",
        "results = model.predict(features)\n",
        "for ind in range(len(imagess)):\n",
        "  # Since we are only testing one image with possible class, we only need to check the first result's first element\n",
        "  single_result = results[ind][0]\n",
        "  \n",
        "  # Print the result\n",
        "  print(\"Image {}: Likelihood that this image contains rain: {}%\".format(ind, int(single_result * 100)))"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Image 0: Likelihood that this image contains rain: 0%\n",
            "Image 1: Likelihood that this image contains rain: 75%\n",
            "Image 2: Likelihood that this image contains rain: 0%\n",
            "Image 3: Likelihood that this image contains rain: 0%\n",
            "Image 4: Likelihood that this image contains rain: 0%\n",
            "Image 5: Likelihood that this image contains rain: 0%\n",
            "Image 6: Likelihood that this image contains rain: 100%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}